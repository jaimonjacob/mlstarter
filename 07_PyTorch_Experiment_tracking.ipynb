{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "07. PyTorch Experiment tracking",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaimonjacob/mlstarter/blob/main/07_PyTorch_Experiment_tracking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download jeffheaton/iris-computer-vision"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:05.505684Z",
          "iopub.execute_input": "2024-11-09T11:44:05.506009Z",
          "iopub.status.idle": "2024-11-09T11:44:07.66987Z",
          "shell.execute_reply.started": "2024-11-09T11:44:05.505974Z",
          "shell.execute_reply": "2024-11-09T11:44:07.668592Z"
        },
        "id": "-YgIpHmaCGjx",
        "outputId": "41824425-9920-4c3a-9a1a-537eacbe0a38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/jeffheaton/iris-computer-vision\n",
            "License(s): GNU Lesser General Public License 3.0\n",
            "Downloading iris-computer-vision.zip to /content\n",
            " 75% 4.00M/5.33M [00:00<00:00, 6.00MB/s]\n",
            "100% 5.33M/5.33M [00:01<00:00, 5.54MB/s]\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q split-folders torchinfo"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:07.672315Z",
          "iopub.execute_input": "2024-11-09T11:44:07.672715Z",
          "iopub.status.idle": "2024-11-09T11:44:20.573343Z",
          "shell.execute_reply.started": "2024-11-09T11:44:07.672657Z",
          "shell.execute_reply": "2024-11-09T11:44:20.572131Z"
        },
        "id": "1tMwRdzVCGjy"
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.magic import register_cell_magic\n",
        "\n",
        "@register_cell_magic\n",
        "def skip(line, cell):\n",
        "    return"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:20.574961Z",
          "iopub.execute_input": "2024-11-09T11:44:20.575354Z",
          "iopub.status.idle": "2024-11-09T11:44:20.580598Z",
          "shell.execute_reply.started": "2024-11-09T11:44:20.575307Z",
          "shell.execute_reply": "2024-11-09T11:44:20.579446Z"
        },
        "id": "V79oY_9lCGjy"
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from torch.utils.tensorboard import SummaryWriter\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find tensorboard... installing it.\")\n",
        "    !pip install -q tensorboard\n",
        "    from torch.utils.tensorboard import SummaryWriter"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:20.583487Z",
          "iopub.execute_input": "2024-11-09T11:44:20.584201Z",
          "iopub.status.idle": "2024-11-09T11:44:35.759402Z",
          "shell.execute_reply.started": "2024-11-09T11:44:20.584162Z",
          "shell.execute_reply": "2024-11-09T11:44:35.758292Z"
        },
        "id": "3J_exVNPCGjy"
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:35.76046Z",
          "iopub.execute_input": "2024-11-09T11:44:35.760999Z",
          "iopub.status.idle": "2024-11-09T11:44:35.766797Z",
          "shell.execute_reply.started": "2024-11-09T11:44:35.760964Z",
          "shell.execute_reply": "2024-11-09T11:44:35.765772Z"
        },
        "id": "oGIwLpuRCGjy"
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from typing import Dict, List, Tuple\n",
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import v2\n",
        "import random\n",
        "from PIL import Image\n",
        "from torchinfo import summary\n",
        "import shutil\n",
        "import matplotlib.image as mpimg\n",
        "import os\n",
        "import splitfolders"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:35.768048Z",
          "iopub.execute_input": "2024-11-09T11:44:35.768347Z",
          "iopub.status.idle": "2024-11-09T11:44:39.070269Z",
          "shell.execute_reply.started": "2024-11-09T11:44:35.768316Z",
          "shell.execute_reply": "2024-11-09T11:44:39.069488Z"
        },
        "id": "JBSw7TV9CGjy"
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:39.07147Z",
          "iopub.execute_input": "2024-11-09T11:44:39.072144Z",
          "iopub.status.idle": "2024-11-09T11:44:39.132542Z",
          "shell.execute_reply.started": "2024-11-09T11:44:39.072109Z",
          "shell.execute_reply": "2024-11-09T11:44:39.131453Z"
        },
        "id": "olvcAyvOCGjz",
        "outputId": "8d8f8538-a688-40f2-9f92-5b1fef6158cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path for the zip file and the destination folder\n",
        "zip_file_path = 'file.zip'\n",
        "destination_folder = 'data'\n",
        "\n",
        "# Create the destination folder if it doesn't exist\n",
        "os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "# Extract the contents of the zip file into the destination folder\n",
        "with zipfile.ZipFile(\"iris-computer-vision.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(destination_folder)\n",
        "\n",
        "print(f\"Extracted {zip_file_path} into {destination_folder}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:39.134166Z",
          "iopub.execute_input": "2024-11-09T11:44:39.134551Z",
          "iopub.status.idle": "2024-11-09T11:44:39.237452Z",
          "shell.execute_reply.started": "2024-11-09T11:44:39.134514Z",
          "shell.execute_reply": "2024-11-09T11:44:39.236578Z"
        },
        "id": "77ldP7MYCGjz",
        "outputId": "6fd90227-93bd-4d20-cc7c-d0b4344025f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/kaggle/working/iris-computer-vision.zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-4ed5227af00b>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Extract the contents of the zip file into the destination folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/working/iris-computer-vision.zip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/working/iris-computer-vision.zip'"
          ]
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf data/images\n",
        "# !rm -rf data/train\n",
        "# !rm -rf data/test\n",
        "# !rm -rf data\n",
        "# !rm -rf data"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:39.238612Z",
          "iopub.execute_input": "2024-11-09T11:44:39.238952Z",
          "iopub.status.idle": "2024-11-09T11:44:39.242884Z",
          "shell.execute_reply.started": "2024-11-09T11:44:39.238918Z",
          "shell.execute_reply": "2024-11-09T11:44:39.241996Z"
        },
        "id": "tdAgl3zrCGjz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "input_folder = \"data\"\n",
        "output = \"/Data\" #where you want the split datasets saved. one will be created if it does not exist or none is set\n",
        "\n",
        "splitfolders.ratio(input_folder, output=output, seed=42, ratio=(.75, .25)) # ratio of split are in order of train/val/test. You can change to whatever you want. For train/val sets only, you could do .75, .25 for example."
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:39.24688Z",
          "iopub.execute_input": "2024-11-09T11:44:39.247274Z",
          "iopub.status.idle": "2024-11-09T11:44:39.320994Z",
          "shell.execute_reply.started": "2024-11-09T11:44:39.24724Z",
          "shell.execute_reply": "2024-11-09T11:44:39.320147Z"
        },
        "id": "5fS9afihCGjz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = Path(\"Data\")\n",
        "\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"val\"\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:39.321992Z",
          "iopub.execute_input": "2024-11-09T11:44:39.32226Z",
          "iopub.status.idle": "2024-11-09T11:44:39.326852Z",
          "shell.execute_reply.started": "2024-11-09T11:44:39.32223Z",
          "shell.execute_reply": "2024-11-09T11:44:39.325935Z"
        },
        "id": "GFHPxThpCGj0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "test_image_path_list = list(test_dir.glob(\"**/*.jpg\")) # Change to the correct image extension if needed"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:39.328523Z",
          "iopub.execute_input": "2024-11-09T11:44:39.329046Z",
          "iopub.status.idle": "2024-11-09T11:44:39.341835Z",
          "shell.execute_reply.started": "2024-11-09T11:44:39.328999Z",
          "shell.execute_reply": "2024-11-09T11:44:39.341Z"
        },
        "collapsed": true,
        "id": "msx0H-YVCGj0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper functions"
      ],
      "metadata": {
        "id": "8rRoNInFCGj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_random_images(folder_path, num_images=10):\n",
        "    # Collect all image paths and their class labels\n",
        "    image_paths = []\n",
        "    class_labels = []\n",
        "\n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            if file.endswith('.jpg') or file.endswith('.png'):\n",
        "                image_paths.append(os.path.join(root, file))\n",
        "                class_labels.append(os.path.basename(root))\n",
        "\n",
        "    # Randomly select the specified number of images\n",
        "    selected_indices = random.sample(range(len(image_paths)), min(num_images, len(image_paths)))\n",
        "    selected_images = [image_paths[i] for i in selected_indices]\n",
        "    selected_labels = [class_labels[i] for i in selected_indices]\n",
        "    print(selected_images)\n",
        "    # Plot the selected images\n",
        "    plt.figure(figsize=(20, 10))\n",
        "    for i in range(len(selected_images)):\n",
        "        img = mpimg.imread(selected_images[i])\n",
        "        plt.subplot(2, 5, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(selected_labels[i])\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:39.342813Z",
          "iopub.execute_input": "2024-11-09T11:44:39.34306Z",
          "iopub.status.idle": "2024-11-09T11:44:39.352365Z",
          "shell.execute_reply.started": "2024-11-09T11:44:39.343033Z",
          "shell.execute_reply": "2024-11-09T11:44:39.351495Z"
        },
        "id": "EWXpVzgYCGj0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to plot transformed images\n",
        "def plot_transformed_images(image_paths, transform, n=3, seed=42):\n",
        "    \"\"\"Plots a series of random images from image_paths.\n",
        "\n",
        "    Will open n image paths from image_paths, transform them\n",
        "    with transform and plot them side by side.\n",
        "\n",
        "    Args:\n",
        "        image_paths (list): List of target image paths.\n",
        "        transform (PyTorch Transforms): Transforms to apply to images.\n",
        "        n (int, optional): Number of images to plot. Defaults to 3.\n",
        "        seed (int, optional): Random seed for the random generator. Defaults to 42.\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    random_image_paths = random.sample(image_paths, k=n)\n",
        "    for image_path in random_image_paths:\n",
        "        with Image.open(image_path) as f:\n",
        "            fig, ax = plt.subplots(1, 2)\n",
        "            ax[0].imshow(f)\n",
        "            ax[0].set_title(f\"Original \\nSize: {f.size}\")\n",
        "            ax[0].axis(\"off\")\n",
        "\n",
        "            # Transform and plot image\n",
        "            # Note: permute() will change shape of image to suit matplotlib\n",
        "            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])\n",
        "            transformed_image = transform(f).permute(1, 2, 0)\n",
        "            ax[1].imshow(transformed_image)\n",
        "            ax[1].set_title(f\"Transformed \\nSize: {transformed_image.shape}\")\n",
        "            ax[1].axis(\"off\")\n",
        "\n",
        "            fig.suptitle(f\"Class: {image_path.parent.stem}\", fontsize=16)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:39.353669Z",
          "iopub.execute_input": "2024-11-09T11:44:39.354023Z",
          "iopub.status.idle": "2024-11-09T11:44:39.362224Z",
          "shell.execute_reply.started": "2024-11-09T11:44:39.353988Z",
          "shell.execute_reply": "2024-11-09T11:44:39.361291Z"
        },
        "id": "2mUWxTy9CGj1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def random_visualize_model_results(model, dataset):\n",
        "    #torch.manual_seed(42)\n",
        "    fig = plt.figure(figsize=(12,12))\n",
        "    rows, cols = 4, 4\n",
        "    for i in range(1, rows*cols+1):\n",
        "        random_idx = torch.randint(0, len(dataset), size=[1]).item()\n",
        "        image, label = dataset[random_idx]\n",
        "        fig.add_subplot(rows, cols, i)\n",
        "        plt.imshow(image.permute(1, 2, 0))\n",
        "        model.eval()\n",
        "        with torch.inference_mode():\n",
        "            y_logits = model(image.unsqueeze(dim=0).to(device))\n",
        "            y_predprobs = torch.softmax(y_logits, dim=1)\n",
        "            y_preds = torch.argmax(y_predprobs, dim=1)\n",
        "            actual_label = class_names[label]\n",
        "            pred_label = class_names[y_preds.item()]\n",
        "        if y_preds.item() == label:\n",
        "            plt.title(f\"Pred: {pred_label} | Actual: {actual_label}\", c=\"g\", fontsize=10)\n",
        "        else:\n",
        "            plt.title(f\"Pred: {pred_label} | Actual: {actual_label}\", c=\"r\", fontsize=10)\n",
        "        plt.axis(False)\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:39.363281Z",
          "iopub.execute_input": "2024-11-09T11:44:39.363673Z",
          "iopub.status.idle": "2024-11-09T11:44:39.374009Z",
          "shell.execute_reply.started": "2024-11-09T11:44:39.363637Z",
          "shell.execute_reply": "2024-11-09T11:44:39.373094Z"
        },
        "id": "5bm1t9IGCGj1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Functionising the training and test loops\n",
        "def train_step(model: nn.Module,\n",
        "               loss_fn: nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device: torch.device=device):\n",
        "     #Initiating the train loss as 0 so that we can add to it with each batch\n",
        "    train_loss = 0\n",
        "    train_accuracy = 0\n",
        "    model.to(device)\n",
        "    #Train loop\n",
        "    #For each epoch, we will iterate through the batches\n",
        "    for batch, (X,y) in enumerate(dataloader):\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        model.train()\n",
        "        #1 forward pass\n",
        "        y_pred = model(X)\n",
        "        #2 Calculate the loss and accuracy per batch\n",
        "        loss = loss_fn(y_pred, y)\n",
        "         # Calculate and accumulate accuracy metric across all batches\n",
        "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "        accuracy = (y_pred_class == y).sum().item()/len(y_pred)\n",
        "        # accuracy = accuracy_fn(y_pred.argmax(dim=1), y)\n",
        "        #Accumulate training loss for every batch\n",
        "        train_loss += loss\n",
        "        train_accuracy += accuracy\n",
        "        #3 Opitmizer zero grad\n",
        "        optimizer.zero_grad()\n",
        "        #4 Loss backward\n",
        "        loss.backward()\n",
        "        #5 Optimizer step. The model's paramters are updated once per batch, not per epoch\n",
        "        optimizer.step()\n",
        "\n",
        "    #Divide total trainig loss/accuracy by length of train data loader - find average\n",
        "    train_loss /= len(train_dataloader)\n",
        "    train_accuracy /= len(train_dataloader)\n",
        "    return train_loss, train_accuracy\n",
        "\n",
        "\n",
        "def test_step(model: nn.Module,\n",
        "              loss_fn: nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              optimizer: torch.optim.Optimizer,\n",
        "              device: torch.device=device):\n",
        "    #Test loop\n",
        "    test_loss = 0\n",
        "    test_accuracy = 0\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for batch, (X,y) in enumerate(dataloader):\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            y_pred = model(X)\n",
        "            #Find accuracy\n",
        "            y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "            accuracy = (y_pred_class == y).sum().item()/len(y_pred)\n",
        "            test_accuracy += accuracy\n",
        "            #2 Calculate the loss per batch\n",
        "            test_loss += loss_fn(y_pred, y)\n",
        "        #Calculate test average loss\n",
        "        test_accuracy /= len(test_dataloader)\n",
        "        #Calculate test average accuracy\n",
        "        test_loss /= len(test_dataloader)\n",
        "    return test_loss, test_accuracy"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:39.37525Z",
          "iopub.execute_input": "2024-11-09T11:44:39.375618Z",
          "iopub.status.idle": "2024-11-09T11:44:39.389097Z",
          "shell.execute_reply.started": "2024-11-09T11:44:39.375587Z",
          "shell.execute_reply": "2024-11-09T11:44:39.388135Z"
        },
        "id": "wYMDvsKVCGj1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a sigle train function\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "# model: nn.Module,\n",
        "# loss_fn: nn.Module,\n",
        "# accuracy_fn,\n",
        "# dataloader: torch.utils.data.DataLoader,\n",
        "# optimizer: torch.optim.Optimizer,\n",
        "# device: torch.device=device):\n",
        "\n",
        "# 1. Take in various parameters required for training and test steps\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module,\n",
        "          epochs: int = 5,\n",
        "          device: device,\n",
        "          writer: torch.utils.tensorboard.writer.SummaryWriter,\n",
        "          ):\n",
        "\n",
        "\n",
        "    results = {\"train_loss\": [],\n",
        "        \"train_acc\": [],\n",
        "        \"test_loss\": [],\n",
        "        \"test_acc\": []\n",
        "    }\n",
        "\n",
        "    train_start_on_gpu = timer()\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss, train_accuracy = train_step(model, loss_fn, train_dataloader, optimizer, device)\n",
        "        test_loss, test_accuracy = test_step(model, loss_fn, test_dataloader, optimizer, device)\n",
        "\n",
        "        print(\n",
        "                f\"Epoch: {epoch} | \"\n",
        "                f\"train_loss: {train_loss:.4f} | \"\n",
        "                f\"train_acc: {train_accuracy:.4f} | \"\n",
        "                f\"test_loss: {test_loss:.4f} | \"\n",
        "                f\"test_acc: {test_accuracy:.4f}\"\n",
        "            )\n",
        "        results[\"train_loss\"].append(train_loss.item())\n",
        "        results[\"train_acc\"].append(train_accuracy)\n",
        "        results[\"test_loss\"].append(test_loss.item())\n",
        "        results[\"test_acc\"].append(test_accuracy)\n",
        "\n",
        "        ### New: Experiment tracking ###\n",
        "        # Add loss results to SummaryWriter\n",
        "        writer.add_scalars(main_tag=\"Loss\",\n",
        "                           tag_scalar_dict={\"train_loss\": train_loss,\n",
        "                                            \"test_loss\": test_loss},\n",
        "                           global_step=epoch)\n",
        "\n",
        "        # Add accuracy results to SummaryWriter\n",
        "        writer.add_scalars(main_tag=\"Accuracy\",\n",
        "                           tag_scalar_dict={\"train_acc\": train_accuracy,\n",
        "                                            \"test_acc\": test_accuracy},\n",
        "                           global_step=epoch)\n",
        "\n",
        "        # Track the PyTorch model architecture\n",
        "        writer.add_graph(model=model,\n",
        "                         # Pass in an example input\n",
        "                         input_to_model=torch.randn(32, 3, 224, 224).to(device))\n",
        "\n",
        "    # Close the writer\n",
        "    writer.close()\n",
        "    ### End new ###\n",
        "\n",
        "\n",
        "    train_end_on_gpu = timer()\n",
        "    total_train_time_model_0 = print_train_time(start=train_start_on_gpu, end=train_end_on_gpu)\n",
        "    return results\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:39.390578Z",
          "iopub.execute_input": "2024-11-09T11:44:39.391219Z",
          "iopub.status.idle": "2024-11-09T11:44:39.403237Z",
          "shell.execute_reply.started": "2024-11-09T11:44:39.391177Z",
          "shell.execute_reply": "2024-11-09T11:44:39.402402Z"
        },
        "id": "lMPPAOd9CGj1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a function to plot loss\n",
        "def plot_loss_curves(results: Dict[str, List[float]]):\n",
        "    \"\"\"Plots training curves of a results dictionary.\n",
        "\n",
        "    Args:\n",
        "        results (dict): dictionary containing list of values, e.g.\n",
        "            {\"train_loss\": [...],\n",
        "             \"train_acc\": [...],\n",
        "             \"test_loss\": [...],\n",
        "             \"test_acc\": [...]}\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the loss values of the results dictionary (training and test)\n",
        "    loss = results['train_loss']\n",
        "    test_loss = results['test_loss']\n",
        "\n",
        "    # Get the accuracy values of the results dictionary (training and test)\n",
        "    accuracy = results['train_acc']\n",
        "    test_accuracy = results['test_acc']\n",
        "\n",
        "    # Figure out how many epochs there were\n",
        "    epochs = range(len(results['train_loss']))\n",
        "\n",
        "    # Setup a plot\n",
        "    plt.figure(figsize=(15, 7))\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, loss, label='train_loss')\n",
        "    plt.plot(epochs, test_loss, label='test_loss')\n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, accuracy, label='train_accuracy')\n",
        "    plt.plot(epochs, test_accuracy, label='test_accuracy')\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend();"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:39.404378Z",
          "iopub.execute_input": "2024-11-09T11:44:39.405014Z",
          "iopub.status.idle": "2024-11-09T11:44:39.414693Z",
          "shell.execute_reply.started": "2024-11-09T11:44:39.404981Z",
          "shell.execute_reply": "2024-11-09T11:44:39.413761Z"
        },
        "id": "-PaCd1CGCGj2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "\n",
        "def print_train_time(start: float,\n",
        "                    end: float,\n",
        "                    device: torch.device=None):\n",
        "    \"\"\"\n",
        "    Prints the different between start and end of training\n",
        "\n",
        "    Args:\n",
        "    Start, end, device\n",
        "\n",
        "    Returns:\n",
        "    Time in string\n",
        "    \"\"\"\n",
        "    total_time = end - start\n",
        "    print (f\"The time spent on training on {device}: {total_time: .3f} seconds\")\n",
        "    return total_time\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:39.415714Z",
          "iopub.execute_input": "2024-11-09T11:44:39.416014Z",
          "iopub.status.idle": "2024-11-09T11:44:39.42207Z",
          "shell.execute_reply.started": "2024-11-09T11:44:39.415984Z",
          "shell.execute_reply": "2024-11-09T11:44:39.42122Z"
        },
        "id": "ZVHTRMPdCGj2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seeds\n",
        "def set_seeds(seed: int=42):\n",
        "    \"\"\"Sets random sets for torch operations.\n",
        "\n",
        "    Args:\n",
        "        seed (int, optional): Random seed to set. Defaults to 42.\n",
        "    \"\"\"\n",
        "    # Set the seed for general torch operations\n",
        "    torch.manual_seed(seed)\n",
        "    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n",
        "    torch.cuda.manual_seed(seed)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:39.423221Z",
          "iopub.execute_input": "2024-11-09T11:44:39.4236Z",
          "iopub.status.idle": "2024-11-09T11:44:39.431471Z",
          "shell.execute_reply.started": "2024-11-09T11:44:39.423551Z",
          "shell.execute_reply": "2024-11-09T11:44:39.43061Z"
        },
        "id": "TKLgeY6iCGj2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def create_writer(experiment_name: str,\n",
        "                  model_name: str,\n",
        "                  extra: str=None) -> torch.utils.tensorboard.writer.SummaryWriter():\n",
        "    \"\"\"Creates a torch.utils.tensorboard.writer.SummaryWriter() instance saving to a specific log_dir.\n",
        "\n",
        "    log_dir is a combination of runs/timestamp/experiment_name/model_name/extra.\n",
        "\n",
        "    Where timestamp is the current date in YYYY-MM-DD format.\n",
        "\n",
        "    Args:\n",
        "        experiment_name (str): Name of experiment.\n",
        "        model_name (str): Name of model.\n",
        "        extra (str, optional): Anything extra to add to the directory. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        torch.utils.tensorboard.writer.SummaryWriter(): Instance of a writer saving to log_dir.\n",
        "\n",
        "    Example usage:\n",
        "        # Create a writer saving to \"runs/2022-06-04/data_10_percent/effnetb2/5_epochs/\"\n",
        "        writer = create_writer(experiment_name=\"data_10_percent\",\n",
        "                               model_name=\"effnetb2\",\n",
        "                               extra=\"5_epochs\")\n",
        "        # The above is the same as:\n",
        "        writer = SummaryWriter(log_dir=\"runs/2022-06-04/data_10_percent/effnetb2/5_epochs/\")\n",
        "    \"\"\"\n",
        "    from datetime import datetime\n",
        "    import os\n",
        "\n",
        "    # Get timestamp of current date (all experiments on certain day live in same folder)\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d\") # returns current date in YYYY-MM-DD format\n",
        "\n",
        "    if extra:\n",
        "        # Create log directory path\n",
        "        log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name, extra)\n",
        "    else:\n",
        "        log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name)\n",
        "\n",
        "    print(f\"[INFO] Created SummaryWriter, saving to: {log_dir}...\")\n",
        "    return SummaryWriter(log_dir=log_dir)"
      ],
      "metadata": {
        "id": "RNyi-31oCluU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize"
      ],
      "metadata": {
        "id": "bJyA4UKoCGj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_random_images(test_dir)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:39.434512Z",
          "iopub.execute_input": "2024-11-09T11:44:39.434935Z",
          "iopub.status.idle": "2024-11-09T11:44:40.763937Z",
          "shell.execute_reply.started": "2024-11-09T11:44:39.434902Z",
          "shell.execute_reply": "2024-11-09T11:44:40.762922Z"
        },
        "id": "xh--5pK-CGj2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_random_images(train_dir)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:40.765216Z",
          "iopub.execute_input": "2024-11-09T11:44:40.765555Z",
          "iopub.status.idle": "2024-11-09T11:44:42.348604Z",
          "shell.execute_reply.started": "2024-11-09T11:44:40.765522Z",
          "shell.execute_reply": "2024-11-09T11:44:42.347433Z"
        },
        "id": "iwRqDxGGCGj3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# USing Efficientnet"
      ],
      "metadata": {
        "id": "Nr-5firvCGj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # .DEFAULT = best available weights from pretraining on ImageNet\n",
        "auto_transforms = weights.transforms()\n",
        "auto_transforms"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:42.350016Z",
          "iopub.execute_input": "2024-11-09T11:44:42.350387Z",
          "iopub.status.idle": "2024-11-09T11:44:42.357651Z",
          "shell.execute_reply.started": "2024-11-09T11:44:42.350348Z",
          "shell.execute_reply": "2024-11-09T11:44:42.356731Z"
        },
        "id": "5IuluTVLCGj3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "manual_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # 1. Reshape all images to 224x224 (though some models may require different sizes)\n",
        "    transforms.ToTensor(), # 2. Turn image values to between 0 & 1\n",
        "])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:42.358904Z",
          "iopub.execute_input": "2024-11-09T11:44:42.359467Z",
          "iopub.status.idle": "2024-11-09T11:44:42.37024Z",
          "shell.execute_reply.started": "2024-11-09T11:44:42.359427Z",
          "shell.execute_reply": "2024-11-09T11:44:42.369327Z"
        },
        "id": "eff78kLMCGj3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load and transform data\n",
        "train_data = datasets.ImageFolder(root=train_dir, transform=auto_transforms )\n",
        "test_data = datasets.ImageFolder(root=test_dir, transform=auto_transforms )\n",
        "class_names = train_data.classes\n",
        "\n",
        "# Setup batch size and number of workers\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "print(f\"Creating DataLoader's with batch size {BATCH_SIZE} and {NUM_WORKERS} workers.\")\n",
        "\n",
        "# Create DataLoader's\n",
        "train_dataloader = DataLoader(train_data,\n",
        "                                     batch_size=BATCH_SIZE,\n",
        "                                     shuffle=True,\n",
        "                                     num_workers=NUM_WORKERS,\n",
        "                              pin_memory=True,)\n",
        "\n",
        "test_dataloader = DataLoader(test_data,\n",
        "                                    batch_size=BATCH_SIZE,\n",
        "                                    shuffle=False,\n",
        "                                    num_workers=NUM_WORKERS,\n",
        "                             pin_memory=True)\n",
        "\n",
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:42.371463Z",
          "iopub.execute_input": "2024-11-09T11:44:42.371896Z",
          "iopub.status.idle": "2024-11-09T11:44:42.386096Z",
          "shell.execute_reply.started": "2024-11-09T11:44:42.371855Z",
          "shell.execute_reply": "2024-11-09T11:44:42.385266Z"
        },
        "id": "GwFyxZ65CGj3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
        "plot_transformed_images(test_image_path_list,\n",
        "                        transform=auto_transforms,\n",
        "                        n=3)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:42.38744Z",
          "iopub.execute_input": "2024-11-09T11:44:42.387825Z",
          "iopub.status.idle": "2024-11-09T11:44:43.399906Z",
          "shell.execute_reply.started": "2024-11-09T11:44:42.387792Z",
          "shell.execute_reply": "2024-11-09T11:44:43.399019Z"
        },
        "id": "6J108mxjCGj4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # .DEFAULT = best available weights\n",
        "model = torchvision.models.efficientnet_b0(weights=weights).to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:43.401088Z",
          "iopub.execute_input": "2024-11-09T11:44:43.401408Z",
          "iopub.status.idle": "2024-11-09T11:44:44.059888Z",
          "shell.execute_reply.started": "2024-11-09T11:44:43.401374Z",
          "shell.execute_reply": "2024-11-09T11:44:44.059069Z"
        },
        "id": "VcjolCyGCGj4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model=model,\n",
        "        input_size=(32, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\"\n",
        "        # col_names=[\"input_size\"], # uncomment for smaller output\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"]\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:44.065368Z",
          "iopub.execute_input": "2024-11-09T11:44:44.06568Z",
          "iopub.status.idle": "2024-11-09T11:44:44.802255Z",
          "shell.execute_reply.started": "2024-11-09T11:44:44.065647Z",
          "shell.execute_reply": "2024-11-09T11:44:44.801307Z"
        },
        "id": "0b5tS6ZSCGj4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all base layers in the \"features\" section of the model (the feature extractor) by setting requires_grad=False\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:44.803515Z",
          "iopub.execute_input": "2024-11-09T11:44:44.803929Z",
          "iopub.status.idle": "2024-11-09T11:44:44.810408Z",
          "shell.execute_reply.started": "2024-11-09T11:44:44.803885Z",
          "shell.execute_reply": "2024-11-09T11:44:44.809309Z"
        },
        "id": "yxoZ87k6CGj4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the manual seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Get the length of class_names (one output unit for each class)\n",
        "output_shape = len(class_names)\n",
        "\n",
        "# Recreate the classifier layer and seed it to the target device\n",
        "model.classifier = torch.nn.Sequential(\n",
        "    torch.nn.Dropout(p=0.2, inplace=True),\n",
        "    torch.nn.Linear(in_features=1280,\n",
        "                    out_features=output_shape, # same number of output units as our number of classes\n",
        "                    bias=True)).to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:44.811718Z",
          "iopub.execute_input": "2024-11-09T11:44:44.812092Z",
          "iopub.status.idle": "2024-11-09T11:44:44.824604Z",
          "shell.execute_reply.started": "2024-11-09T11:44:44.812051Z",
          "shell.execute_reply": "2024-11-09T11:44:44.823688Z"
        },
        "id": "k4vWW85eCGj4",
        "outputId": "e380299c-9549-4df7-86aa-12e1792a472e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'class_names' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-800944e6a609>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Get the length of class_names (one output unit for each class)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Recreate the classifier layer and seed it to the target device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'class_names' is not defined"
          ]
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": [
        "# # Do a summary *after* freezing the features and changing the output classifier layer (uncomment for actual output)\n",
        "summary(model,\n",
        "        input_size=(32, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\" (batch_size, color_channels, height, width)\n",
        "        verbose=0,\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"]\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:44.825751Z",
          "iopub.execute_input": "2024-11-09T11:44:44.826024Z",
          "iopub.status.idle": "2024-11-09T11:44:44.974033Z",
          "shell.execute_reply.started": "2024-11-09T11:44:44.825994Z",
          "shell.execute_reply": "2024-11-09T11:44:44.973089Z"
        },
        "id": "RnwdCsrKCGj5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "random_visualize_model_results(model, test_data)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:44.975192Z",
          "iopub.execute_input": "2024-11-09T11:44:44.975494Z",
          "iopub.status.idle": "2024-11-09T11:44:47.030751Z",
          "shell.execute_reply.started": "2024-11-09T11:44:44.975465Z",
          "shell.execute_reply": "2024-11-09T11:44:47.029858Z"
        },
        "id": "gFwfUVdCCGj5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn_0 = nn.CrossEntropyLoss()\n",
        "optimizer_0 = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:47.031944Z",
          "iopub.execute_input": "2024-11-09T11:44:47.032261Z",
          "iopub.status.idle": "2024-11-09T11:44:47.038787Z",
          "shell.execute_reply.started": "2024-11-09T11:44:47.032227Z",
          "shell.execute_reply": "2024-11-09T11:44:47.037882Z"
        },
        "id": "6Oq0O3nVCGj5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an example writer\n",
        "example_writer = create_writer(experiment_name=\"data_iris-computer-vision\",\n",
        "                               model_name=\"effnetb0\",\n",
        "                               extra=\"10_epochs\")"
      ],
      "metadata": {
        "id": "wxb8oWs_DDxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seeds()\n",
        "model_results = train(model = model,\n",
        "          train_dataloader = train_dataloader,\n",
        "          test_dataloader = test_dataloader,\n",
        "          optimizer = optimizer_0,\n",
        "          loss_fn = loss_fn_0,\n",
        "          epochs = 10,\n",
        "          writer = example_writer)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:44:47.040129Z",
          "iopub.execute_input": "2024-11-09T11:44:47.040526Z",
          "iopub.status.idle": "2024-11-09T11:45:30.207037Z",
          "shell.execute_reply.started": "2024-11-09T11:44:47.040486Z",
          "shell.execute_reply": "2024-11-09T11:45:30.205784Z"
        },
        "id": "j4jFbz-uCGj5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-09T11:45:30.208568Z",
          "iopub.execute_input": "2024-11-09T11:45:30.208963Z",
          "iopub.status.idle": "2024-11-09T11:45:36.243989Z",
          "shell.execute_reply.started": "2024-11-09T11:45:30.208923Z",
          "shell.execute_reply": "2024-11-09T11:45:36.243031Z"
        },
        "id": "Rb_KpSHOCGj5"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}